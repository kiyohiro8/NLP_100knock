{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章: ニューラルネット\n",
    "自然言語処理100本ノック (https://nlp100.github.io/ja/) の第8章です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70. 単語ベクトルの和による特徴量\n",
    "長いので省略するが、問題50で扱った記事見出し-カテゴリデータについて、\n",
    "記事の特徴量を各単語ベクトルの平均を取れとのこと"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>category</th>\n",
       "      <th>story</th>\n",
       "      <th>hostname</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "id                                                      \n",
       "1   Fed official says weak data caused by weather,...   \n",
       "2   Fed's Charles Plosser sees high bar for change...   \n",
       "3   US open: Stocks fall after Fed official hints ...   \n",
       "4   Fed risks falling 'behind the curve', Charles ...   \n",
       "5   Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                  url          publisher  \\\n",
       "id                                                                         \n",
       "1   http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "2   http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "3   http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "4   http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "5   http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "   category                          story             hostname      timestamp  \n",
       "id                                                                              \n",
       "1         b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "2         b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "3         b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "4         b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "5         b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"NewsAggregatorDataset/newsCorpora.csv\", sep=\"\\t\", index_col=0, names=[\"id\", \"title\", \"url\", \"publisher\", \"category\", \"story\", \"hostname\", \"timestamp\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_seq_feature(text):\n",
    "    word_list = text.split(\" \")\n",
    "    word_list = [w.rstrip(\",\") for w in word_list]\n",
    "    word_list = [w.rstrip(\",\") for w in word_list]\n",
    "    word_list = [w for w in word_list if w in model.vocab.keys()]\n",
    "    if len(word_list) == 0:\n",
    "        word_list = [\"%\"]\n",
    "    feature_array = np.array([model[w] for w in word_list])\n",
    "    seq_feature = feature_array.mean(axis=0)\n",
    "    return seq_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ビジネス (b) を 0、科学技術 (t) を 1、エンターテインメント (e) を 2、健康 (m) を 3 にエンコードする "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def cat_encoder(cat):\n",
    "    if cat == \"b\":\n",
    "        return 0\n",
    "    elif cat == \"t\":\n",
    "        return 1\n",
    "    elif cat == \"e\":\n",
    "        return 2\n",
    "    elif cat == \"m\":\n",
    "        return 3\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "cat_list = [\"m\", \"e\", \"t\", \"b\"]\n",
    "print([cat_encoder(c) for c in cat_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_to_X_y(df):\n",
    "    text_list = list(df[\"title\"])\n",
    "    features = [create_seq_feature(t) for t in text_list]\n",
    "    X = np.stack(features, axis=0)\n",
    "    cat_list = list(df[\"category\"])\n",
    "    y = np.array([cat_encoder(c) for c in cat_list])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6章と同様にしてテーブルを分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10672\n",
      "1334\n",
      "1334\n"
     ]
    }
   ],
   "source": [
    "valid_publisher = [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]\n",
    "df = df.loc[df[\"publisher\"].isin(valid_publisher), :]\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "total_size = len(df)\n",
    "train_size = int(0.8*total_size)\n",
    "valid_size = int(0.1*total_size)\n",
    "test_size = total_size - train_size - valid_size\n",
    "\n",
    "train_df = df.iloc[:train_size, :]\n",
    "valid_df = df.iloc[train_size:train_size+valid_size, :]\n",
    "test_df = df.iloc[train_size+valid_size:, :]\n",
    "\n",
    "\n",
    "print(len(train_df))\n",
    "print(len(valid_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train, y_train = table_to_X_y(train_df)\n",
    "X_val, y_val = table_to_X_y(valid_df)\n",
    "X_test, y_test = table_to_X_y(test_df)\n",
    "\n",
    "np.save( \"train.npy\", np.concatenate([X_train, y_train[:, None]], axis=1))\n",
    "np.save( \"val.npy\", np.concatenate([X_val, y_val[:, None]], axis=1))\n",
    "np.save( \"test.npy\", np.concatenate([X_test, y_test[:, None]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10672, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71. 単層ニューラルネットワークによる予測\n",
    "問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．\n",
    "\n",
    "ここも問題文が長いので省略するが、単層の全結合層＋softmaxの出力を取れと書いてある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SingleLayerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(300, 4, bias=False)\n",
    "        self.active = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.active(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2475, 0.2523, 0.2559, 0.2443],\n",
      "        [0.2322, 0.2691, 0.2484, 0.2504],\n",
      "        [0.2298, 0.2634, 0.2650, 0.2418],\n",
      "        [0.2563, 0.2512, 0.2430, 0.2495]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "slnn = SingleLayerNN()\n",
    "\n",
    "x = torch.from_numpy(X_train[0:4, :].astype(np.float32)).clone()\n",
    "\n",
    "y = slnn(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72. 損失と勾配の計算\n",
    "学習データの事例x1\n",
    "と事例集合x1,x2,x3,x4\n",
    "に対して，クロスエントロピー損失と，行列W\n",
    "に対する勾配を計算せよ．なお，ある事例xi\n",
    "に対して損失は次式で計算される．\n",
    "\n",
    "li=−log[事例xiがyiに分類される確率]\n",
    "ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0002, -0.0071,  0.0006,  ...,  0.0063, -0.0078,  0.0109],\n",
      "        [ 0.0004,  0.0026, -0.0024,  ..., -0.0040,  0.0032, -0.0058],\n",
      "        [-0.0009,  0.0021,  0.0042,  ...,  0.0014,  0.0015,  0.0004],\n",
      "        [ 0.0003,  0.0024, -0.0023,  ..., -0.0037,  0.0030, -0.0055]])\n"
     ]
    }
   ],
   "source": [
    "cel = nn.CrossEntropyLoss()\n",
    "\n",
    "x = torch.from_numpy(X_train[0:4, :].astype(np.float32)).clone()\n",
    "y_pred = slnn(x)\n",
    "\n",
    "loss = cel(y_pred, torch.LongTensor(y_train[0:4]))\n",
    "loss.backward()\n",
    "\n",
    "print(slnn.linear.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73. 確率的勾配降下法による学習\n",
    "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列W\n",
    "を学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "slnn = SingleLayerNN()\n",
    "cel = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(slnn.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(100):\n",
    "    x = torch.from_numpy(X_train.astype(np.float32)).clone()\n",
    "    y_pred = slnn(x)\n",
    "    loss = cel(y_pred, torch.LongTensor(y_train))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 74. 正解率の計測\n",
    "問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習データでの正解率は0.25384182908545727\n",
      "評価データでの正解率は0.25262368815592207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_train = torch.from_numpy(X_train.astype(np.float32)).clone()\n",
    "    y_train_pred = slnn(x_train).numpy().argmax(axis=1)\n",
    "    x_test = torch.from_numpy(X_test.astype(np.float32)).clone()\n",
    "    y_test_pred = slnn(x_test).numpy().argmax(axis=1)\n",
    "acc_train = np.equal(y_train_pred, y_train).mean()\n",
    "acc_test = np.equal(y_test_pred, y_test).mean()\n",
    "    \n",
    "print(f\"学習データでの正解率は{acc_train}\")\n",
    "print(f\"評価データでの正解率は{acc_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
